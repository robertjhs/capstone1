# EthiCars
## The Social Dilemma of Autonomous Vehicles

### Description
Autonomous vehicles should make transportation safer but there will be unavoidable accidents happening due to technical failure or unexpected events. What choice should the AI algorithm make from two horrible outcomes? Should it sacrifice the passengers by avoiding hitting someone on the road, or should it hit a dog or a doctor walking on the pedestrian crossing? These and similar scenarios are the subjects of MIT’s “Moral Machine” project that collects humans’ choices in an online survey to help the development of “ethical” AI decision making.

I'm going to analyze the responses to various scenarios and try to understand and visualize how this information could influence decision making of a machine learning algorithm.

### Sources
Moral Machine project - https://www.moralmachine.net/
The social dilemma of autonomous vehicles - https://www.media.mit.edu/publications/the-social-dilemma-of-autonomous-vehicles/
Moral Machine dataset on OSF - https://osf.io/3hvt2/?view_only=4bb49492edee4a8eb1758552a362a2cf

